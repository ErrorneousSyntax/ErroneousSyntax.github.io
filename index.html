<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dimensionality Reduction in Clustering</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 40px;
            background-color: #f9f9f9;
            color: #333;
        }
        .content {
            max-width: 800px;
            margin: auto;
            padding: 20px;
            background-color: #fff;
            border-radius: 10px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        h1 {
            text-align: center;
            color: #2c3e50;
        }
    </style>
</head>
<body>
    <div class="content">
        <h1>Dimensionality Reduction to identify patterns in the high-dimensionality data</h1>
        <p>
            For those of you in DE1, taking the engineering mathematics module, I will hopefully explain how 
            the "abstract maths" you are learning now is applied very heavily and even in rigorous recent research in 
            data science, hopefully propelling your interest in the subject. I will introduce an advanced topic called 
            dimentionality reduction, which can be vital as Design Engineers to identify patterns and 
            relationships in data to make accurate, informed decisions.
        </p>
        <p>
            In data science, we often attempt to find insights from big data, looking for
            hidden patterns and relationships. However, with datasets containing more than 3 
            features, one must consider a graph of high-dimensions (such as a graph with 100 Dimensionality).
            However the human mind simply cannot comprehend this, yet so visualising this sort
            of data is becoming increasingly important. 
        </p>
    <div class="content">
        <h2>3D Visualization of 15 Clusters</h2>
        <p>
            To attempt to understand why dimentionality reduction to find clusters is important, 
            we shall start with a simple 3d graph with artificial clusters. (Note that it is easy
            to identify clusters in low Dimensionality as seen here, but is impossible beyond 4 dimensions.)
        </p>
        <iframe src="plot_3d.html" width="100%" height="500" style="border:none;"></iframe>
        <p>
            To simulate a very rudimentary dimentionality reduction, imagine the view of this
            graph on your 2D screen is a representation of the data in lower dimentions.
            In any angle, there are overlapping clusters, and even more evidently, the "depth" distance
            between clusters is not preserved in this manner. 
        </p>
        <p>
            Thus, we need a more robust algorithm that embeds high-D data with as much accuracy
            and faithfulness to the original topology of the data. We call this type of dimentionality 
            reduction techniques manifold learning techniques. 
        </p>
        <p>
            Manifold learning techniques assume high-dimentional data lies on a lower-dimentional,
            non-linear structure called a manifold. This means that the general patterns of any dimentionality data can be
            represented to a large extent with lower-dimensionality graphs. 
        </p>
        <p>
            A type of manifold learning techniques is called t-distributed Stochastic Neighbor Embedding.
            t-distributed since it uses the student's t-distribution with 1 degree of freedom (Cauchy distribution)
            to model the similiarities between data points in the low-dimensional embedding space. Stochastic referring
            to the nature of the embedding process using stochastic gradient descent to minimise the Kullback-Leiber divergence between
            the probabilistic models of the "membership strengths" between datapoints in high dimensions and
            low dimensions. Finally Neighbor embedding refers to the nature of t-SNE which embeds local "neighborhoods"
            of datapoints very faithfully into lower dimension graphs. We will explain each step in more detail further down this article.
        </p>
        <h2>2D t-SNE Visualization of 15 Clusters</h2>
        <iframe src="plot_2d.html" width="100%" height="500" style="border:none;"></iframe>
</body>

</html>
